{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eb7973b-a2df-4522-8c4c-4aa00f895b0b",
   "metadata": {},
   "source": [
    "## Import necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce2cbb4f-e38e-4958-b313-cd04394d98c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\ProgramData\\sagemaker\\sagemaker\\config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\Users\\tochi\\AppData\\Local\\sagemaker\\sagemaker\\config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.sklearn import SKLearn\n",
    "from sagemaker.local import LocalSession\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dae24e-85dd-41e7-b305-36bb006a5c3a",
   "metadata": {},
   "source": [
    "## Specify sagemaker session and role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0fce969-bbfc-477f-9c07-ccc4b0c0049e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Windows Support for Local Mode is Experimental\n"
     ]
    }
   ],
   "source": [
    "sagemaker_local_session = LocalSession()\n",
    "sagemaker_local_session.config = {'local': {'local_code': True}}\n",
    "account = boto3.client('sts').get_caller_identity().get('Account')\n",
    "role = f\"arn:aws:iam::{account}:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "875c047e-730a-46af-89cb-45785e5fe710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "# !aws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-2.amazonaws.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fe0b4a-4f38-4226-adb9-daf875a78a27",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Train the model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89a11f45-f79b-4631-976d-0210e1524994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Windows Support for Local Mode is Experimental\n"
     ]
    }
   ],
   "source": [
    "training_input_path = \"s3://modeldata1234567/train/train.csv\"\n",
    "local_output_path = 'file:///Users/tochi/OneDrive/Documents/Train_with_Sagemaker_locally/trained_model'\n",
    "remote_output_path = 's3://sagemaker-us-east-2-930627915954/local_model/'\n",
    "sk_estimator = SKLearn(\n",
    "    session=sagemaker_local_session,\n",
    "    entry_point=\"train.py\", \n",
    "    role=role,\n",
    "    job_name = \"local_training\",\n",
    "    instance_count=1,\n",
    "    train_instance_type='local',\n",
    "    py_version=\"py3\",\n",
    "    framework_version=\"1.2-1\",\n",
    "    hyperparameters={\"n_estimators\":4},\n",
    "    output_path = output_path\n",
    ")\n",
    "sk_estimator.fit({'train': training_input_path}) #mention that the input data has to come from s3 bucket for the training to be successful \n",
    "#because of the way the train.py file is written.if you use local dataset, it will probably break. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae02d483-ef63-4549-9643-b77b86231b09",
   "metadata": {},
   "source": [
    "## Deploy Model Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "652f6534-26b5-43ab-b730-905805549958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-scikit-learn-2024-09-05-01-52-26-374\n",
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker:Creating endpoint-config with name sagemaker-scikit-learn-2024-09-05-01-52-26-374\n",
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-scikit-learn-2024-09-05-01-52-26-374\n",
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker.local.image:'Docker Compose' found using Docker CLI.\n",
      "INFO:sagemaker.local.image:serving\n",
      "INFO:sagemaker.local.image:creating hosting dir in C:\\Users\\tochi\\AppData\\Local\\Temp\\tmpe6sc9lwp\n",
      "INFO:sagemaker.local.image:Using the long-lived AWS credentials found in session\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-bfnyq:\n",
      "    command: serve\n",
      "    container_name: 80dn093ra9-algo-1-bfnyq\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: 257758044811.dkr.ecr.us-east-2.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-bfnyq\n",
      "    ports:\n",
      "    - 8080:8080\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - C:\\Users\\tochi\\OneDrive\\Documents\\Train_with_Sagemaker_locally\\trained_model:/opt/ml/model\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker compose -f C:\\Users\\tochi\\AppData\\Local\\Temp\\tmpe6sc9lwp\\docker-compose.yaml up --build --abort-on-container-exit\n",
      "INFO:sagemaker.local.entities:Checking if serving container is up, attempt: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to 80dn093ra9-algo-1-bfnyq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.local.entities:Container still not up, got: 502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80dn093ra9-algo-1-bfnyq  | 2024-09-05 01:52:29,316 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "80dn093ra9-algo-1-bfnyq  | 2024-09-05 01:52:29,317 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "80dn093ra9-algo-1-bfnyq  | 2024-09-05 01:52:29,318 INFO - sagemaker-containers - nginx config: \n",
      "80dn093ra9-algo-1-bfnyq  | worker_processes auto;\n",
      "80dn093ra9-algo-1-bfnyq  | daemon off;\n",
      "80dn093ra9-algo-1-bfnyq  | pid /tmp/nginx.pid;\n",
      "80dn093ra9-algo-1-bfnyq  | error_log  /dev/stderr;\n",
      "80dn093ra9-algo-1-bfnyq  | \n",
      "80dn093ra9-algo-1-bfnyq  | worker_rlimit_nofile 4096;\n",
      "80dn093ra9-algo-1-bfnyq  | \n",
      "80dn093ra9-algo-1-bfnyq  | events {\n",
      "80dn093ra9-algo-1-bfnyq  |   worker_connections 2048;\n",
      "80dn093ra9-algo-1-bfnyq  | }\n",
      "80dn093ra9-algo-1-bfnyq  | \n",
      "80dn093ra9-algo-1-bfnyq  | http {\n",
      "80dn093ra9-algo-1-bfnyq  |   include /etc/nginx/mime.types;\n",
      "80dn093ra9-algo-1-bfnyq  |   default_type application/octet-stream;\n",
      "80dn093ra9-algo-1-bfnyq  |   access_log /dev/stdout combined;\n",
      "80dn093ra9-algo-1-bfnyq  | \n",
      "80dn093ra9-algo-1-bfnyq  |   upstream gunicorn {\n",
      "80dn093ra9-algo-1-bfnyq  |     server unix:/tmp/gunicorn.sock;\n",
      "80dn093ra9-algo-1-bfnyq  |   }\n",
      "80dn093ra9-algo-1-bfnyq  | \n",
      "80dn093ra9-algo-1-bfnyq  |   server {\n",
      "80dn093ra9-algo-1-bfnyq  |     listen 8080 deferred;\n",
      "80dn093ra9-algo-1-bfnyq  |     client_max_body_size 0;\n",
      "80dn093ra9-algo-1-bfnyq  | \n",
      "80dn093ra9-algo-1-bfnyq  |     keepalive_timeout 3;\n",
      "80dn093ra9-algo-1-bfnyq  | \n",
      "80dn093ra9-algo-1-bfnyq  |     location ~ ^/(ping|invocations|execution-parameters) {\n",
      "80dn093ra9-algo-1-bfnyq  |       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "80dn093ra9-algo-1-bfnyq  |       proxy_set_header Host $http_host;\n",
      "80dn093ra9-algo-1-bfnyq  |       proxy_redirect off;\n",
      "80dn093ra9-algo-1-bfnyq  |       proxy_read_timeout 60s;\n",
      "80dn093ra9-algo-1-bfnyq  |       proxy_pass http://gunicorn;\n",
      "80dn093ra9-algo-1-bfnyq  |     }\n",
      "80dn093ra9-algo-1-bfnyq  | \n",
      "80dn093ra9-algo-1-bfnyq  |     location / {\n",
      "80dn093ra9-algo-1-bfnyq  |       return 404 \"{}\";\n",
      "80dn093ra9-algo-1-bfnyq  |     }\n",
      "80dn093ra9-algo-1-bfnyq  | \n",
      "80dn093ra9-algo-1-bfnyq  |   }\n",
      "80dn093ra9-algo-1-bfnyq  | }\n",
      "80dn093ra9-algo-1-bfnyq  | \n",
      "80dn093ra9-algo-1-bfnyq  | \n",
      "80dn093ra9-algo-1-bfnyq  | 2024/09/05 01:52:29 [crit] 31#31: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "80dn093ra9-algo-1-bfnyq  | 172.18.0.1 - - [05/Sep/2024:01:52:29 +0000] \"GET /ping HTTP/1.1\" 502 166 \"-\" \"python-urllib3/2.2.2\"\n",
      "80dn093ra9-algo-1-bfnyq  | 2024-09-05 01:52:29,630 INFO - sagemaker-containers - Module train does not provide a setup.py. \n",
      "80dn093ra9-algo-1-bfnyq  | Generating setup.py\n",
      "80dn093ra9-algo-1-bfnyq  | 2024-09-05 01:52:29,631 INFO - sagemaker-containers - Generating setup.cfg\n",
      "80dn093ra9-algo-1-bfnyq  | 2024-09-05 01:52:29,631 INFO - sagemaker-containers - Generating MANIFEST.in\n",
      "80dn093ra9-algo-1-bfnyq  | 2024-09-05 01:52:29,631 INFO - sagemaker-containers - Installing module with the following command:\n",
      "80dn093ra9-algo-1-bfnyq  | /miniconda3/bin/python -m pip install . \n",
      "80dn093ra9-algo-1-bfnyq  | Processing /opt/ml/code\n",
      "80dn093ra9-algo-1-bfnyq  |   Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "80dn093ra9-algo-1-bfnyq  | \u001b[?25hBuilding wheels for collected packages: train\n",
      "80dn093ra9-algo-1-bfnyq  |   Building wheel for train (setup.py) ... \u001b[?25ldone\n",
      "80dn093ra9-algo-1-bfnyq  | \u001b[?25h  Created wheel for train: filename=train-1.0.0-py2.py3-none-any.whl size=4299 sha256=6fb42ee9f1352adff20f677af134b7b3a894f1065d8154c30a98ecf64c2c7abc\n",
      "80dn093ra9-algo-1-bfnyq  |   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-8k4xsi4w/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\n",
      "80dn093ra9-algo-1-bfnyq  | Successfully built train\n",
      "80dn093ra9-algo-1-bfnyq  | Installing collected packages: train\n",
      "80dn093ra9-algo-1-bfnyq  | Successfully installed train-1.0.0\n",
      "80dn093ra9-algo-1-bfnyq  | [2024-09-05 01:52:30 +0000] [81] [INFO] Starting gunicorn 20.0.4\n",
      "80dn093ra9-algo-1-bfnyq  | [2024-09-05 01:52:30 +0000] [81] [INFO] Listening at: unix:/tmp/gunicorn.sock (81)\n",
      "80dn093ra9-algo-1-bfnyq  | [2024-09-05 01:52:30 +0000] [81] [INFO] Using worker: gevent\n",
      "80dn093ra9-algo-1-bfnyq  | [2024-09-05 01:52:30 +0000] [83] [INFO] Booting worker with pid: 83\n",
      "80dn093ra9-algo-1-bfnyq  | [2024-09-05 01:52:31 +0000] [84] [INFO] Booting worker with pid: 84\n",
      "80dn093ra9-algo-1-bfnyq  | [2024-09-05 01:52:31 +0000] [85] [INFO] Booting worker with pid: 85\n",
      "80dn093ra9-algo-1-bfnyq  | [2024-09-05 01:52:31 +0000] [86] [INFO] Booting worker with pid: 86\n",
      "80dn093ra9-algo-1-bfnyq  | [2024-09-05 01:52:31 +0000] [106] [INFO] Booting worker with pid: 106\n",
      "80dn093ra9-algo-1-bfnyq  | [2024-09-05 01:52:31 +0000] [107] [INFO] Booting worker with pid: 107\n",
      "80dn093ra9-algo-1-bfnyq  | [2024-09-05 01:52:31 +0000] [108] [INFO] Booting worker with pid: 108\n",
      "80dn093ra9-algo-1-bfnyq  | [2024-09-05 01:52:31 +0000] [147] [INFO] Booting worker with pid: 147\n",
      "80dn093ra9-algo-1-bfnyq  | [2024-09-05 01:52:31 +0000] [167] [INFO] Booting worker with pid: 167\n",
      "80dn093ra9-algo-1-bfnyq  | [2024-09-05 01:52:31 +0000] [168] [INFO] Booting worker with pid: 168\n",
      "80dn093ra9-algo-1-bfnyq  | [2024-09-05 01:52:31 +0000] [169] [INFO] Booting worker with pid: 169\n",
      "80dn093ra9-algo-1-bfnyq  | [2024-09-05 01:52:31 +0000] [208] [INFO] Booting worker with pid: 208\n",
      "80dn093ra9-algo-1-bfnyq  | [2024-09-05 01:52:31 +0000] [209] [INFO] Booting worker with pid: 209\n",
      "80dn093ra9-algo-1-bfnyq  | [2024-09-05 01:52:31 +0000] [211] [INFO] Booting worker with pid: 211\n",
      "80dn093ra9-algo-1-bfnyq  | [2024-09-05 01:52:31 +0000] [212] [INFO] Booting worker with pid: 212\n",
      "80dn093ra9-algo-1-bfnyq  | [2024-09-05 01:52:31 +0000] [213] [INFO] Booting worker with pid: 213\n",
      "80dn093ra9-algo-1-bfnyq  | [2024-09-05 01:52:31 +0000] [233] [INFO] Booting worker with pid: 233\n",
      "80dn093ra9-algo-1-bfnyq  | [2024-09-05 01:52:31 +0000] [267] [INFO] Booting worker with pid: 267\n",
      "80dn093ra9-algo-1-bfnyq  | [2024-09-05 01:52:31 +0000] [273] [INFO] Booting worker with pid: 273\n",
      "80dn093ra9-algo-1-bfnyq  | [2024-09-05 01:52:32 +0000] [294] [INFO] Booting worker with pid: 294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.local.entities:Checking if serving container is up, attempt: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80dn093ra9-algo-1-bfnyq  | 2024-09-05 01:52:34,414 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "80dn093ra9-algo-1-bfnyq  | 172.18.0.1 - - [05/Sep/2024:01:52:34 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"python-urllib3/2.2.2\"\n",
      "!"
     ]
    }
   ],
   "source": [
    "predictor = sk_estimator.deploy(initial_instance_count=1, instance_type=\"local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ad2328-171e-4307-bd52-77814d3dfa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "## talk about the serving container. Use this opportunity to tell viewers that if they check the containers\n",
    "## they will see that another container has spun up . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbbc96e-c164-4838-bcc6-70415564c83a",
   "metadata": {},
   "source": [
    "## Test the local deployed endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5dc85a3-9ace-46a1-bb21-3bd9d741e06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                6.1               2.8                4.7               1.2   \n",
       "1                5.7               3.8                1.7               0.3   \n",
       "2                7.7               2.6                6.9               2.3   \n",
       "3                6.0               2.9                4.5               1.5   \n",
       "4                6.8               2.8                4.8               1.4   \n",
       "\n",
       "   label  \n",
       "0      1  \n",
       "1      0  \n",
       "2      2  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"data/iris_test.csv\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "376c5d3c-0758-47b7-af79-1c06b426721e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                6.1               2.8                4.7               1.2\n",
       "1                5.7               3.8                1.7               0.3\n",
       "2                7.7               2.6                6.9               2.3\n",
       "3                6.0               2.9                4.5               1.5\n",
       "4                6.8               2.8                4.8               1.4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = test_data.drop('label', axis = 1)\n",
    "pred_values = test_data['label']\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70be890b-c73d-4ef6-aff4-b9fcc4d9602a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 1 0 2 2 2 2 2 0 0]80dn093ra9-algo-1-bfnyq  | 172.18.0.1 - - [05/Sep/2024:01:59:26 +0000] \"POST /invocations HTTP/1.1\" 200 368 \"-\" \"python-urllib3/2.2.2\"\n",
      "\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n",
      "80dn093ra9-algo-1-bfnyq  | 172.18.0.1 - - [05/Sep/2024:02:01:45 +0000] \"GET / HTTP/1.1\" 404 2 \"-\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36 Edg/128.0.0.0\"\n",
      "80dn093ra9-algo-1-bfnyq  | 172.18.0.1 - - [05/Sep/2024:02:11:45 +0000] \"GET / HTTP/1.1\" 404 2 \"-\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36 Edg/128.0.0.0\"\n"
     ]
    }
   ],
   "source": [
    "print(predictor.predict(test_df.values))\n",
    "print(pred_values.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0bf233-a6ee-4048-86e3-9e739b512992",
   "metadata": {},
   "source": [
    "##\n",
    "\n",
    "I genuienly want to keep things simple on my channel. so am considering having like having a slide that explains things to people in an easy way\n",
    "I also intentionally want to be focused on passing my message than asthetics and only use pictures where necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8930d5-6039-4377-8107-5c4d93935899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f09624-235b-4c7f-a1b7-62ebf290cf31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker-dev",
   "language": "python",
   "name": "sagemaker-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
